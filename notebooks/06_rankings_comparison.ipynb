{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rankings Comparison: ML vs FanGraphs vs ESPN\n",
    "\n",
    "This notebook compares three ranking systems:\n",
    "- **ML Model** (PAR-adjusted): Our machine learning predictions with positional adjustments\n",
    "- **FanGraphs** (PAR-adjusted): Averaged projections from Steamer, BatX, OOPSY\n",
    "- **ESPN**: ESPN's official 2026 fantasy rankings\n",
    "\n",
    "We'll analyze correlations, identify where systems agree/disagree, and visualize the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Load master rankings\n",
    "df = pd.read_csv('../predictions/master_rankings_2026.csv')\n",
    "print(f\"Total players: {len(df)}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "df = df.rename(columns={\n",
    "    'ML_PAR_Rank': 'ML_Rank',\n",
    "    'Proj_PAR_Rank': 'FG_Rank',\n",
    "})\n",
    "\n",
    "# Focus on the three main ranking columns\n",
    "rank_cols = ['ML_Rank', 'FG_Rank', 'ESPN_Rank']\n",
    "\n",
    "# Filter to players ranked by ESPN (not the default 300)\n",
    "# This gives us a cleaner comparison set\n",
    "espn_ranked = df[df['ESPN_Rank'] < 300].copy()\n",
    "print(f\"Players ranked by ESPN: {len(espn_ranked)}\")\n",
    "print(f\"Players NOT ranked by ESPN: {len(df) - len(espn_ranked)}\")\n",
    "\n",
    "# Create difference columns\n",
    "df['ML_vs_ESPN'] = df['ESPN_Rank'] - df['ML_Rank']  # Positive = ML ranks higher\n",
    "df['FG_vs_ESPN'] = df['ESPN_Rank'] - df['FG_Rank']  # Positive = FG ranks higher\n",
    "df['ML_vs_FG'] = df['FG_Rank'] - df['ML_Rank']      # Positive = ML ranks higher\n",
    "\n",
    "espn_ranked['ML_vs_ESPN'] = espn_ranked['ESPN_Rank'] - espn_ranked['ML_Rank']\n",
    "espn_ranked['FG_vs_ESPN'] = espn_ranked['ESPN_Rank'] - espn_ranked['FG_Rank']\n",
    "espn_ranked['ML_vs_FG'] = espn_ranked['FG_Rank'] - espn_ranked['ML_Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overall Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for ESPN-ranked players\n",
    "corr_matrix = espn_ranked[rank_cols].corr(method='spearman')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdYlGn', center=0.5, \n",
    "            fmt='.3f', square=True, ax=ax,\n",
    "            vmin=0, vmax=1)\n",
    "ax.set_title('Spearman Rank Correlations (ESPN-Ranked Players)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSpearman correlations:\")\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlations for comparison\n",
    "corr_pearson = espn_ranked[rank_cols].corr(method='pearson')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdYlGn', center=0.5,\n",
    "            fmt='.3f', square=True, ax=axes[0], vmin=0, vmax=1)\n",
    "axes[0].set_title('Spearman (Rank-based)', fontsize=12)\n",
    "\n",
    "sns.heatmap(corr_pearson, annot=True, cmap='RdYlGn', center=0.5,\n",
    "            fmt='.3f', square=True, ax=axes[1], vmin=0, vmax=1)\n",
    "axes[1].set_title('Pearson (Linear)', fontsize=12)\n",
    "\n",
    "plt.suptitle('Correlation Comparison: Spearman vs Pearson', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pairwise Scatter Plots with Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML vs ESPN\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.regplot(data=espn_ranked, x='ESPN_Rank', y='ML_Rank', \n",
    "            scatter_kws={'alpha': 0.5, 's': 30},\n",
    "            line_kws={'color': 'red', 'linewidth': 2},\n",
    "            ax=ax)\n",
    "\n",
    "# Add perfect agreement line\n",
    "max_rank = max(espn_ranked['ESPN_Rank'].max(), espn_ranked['ML_Rank'].max())\n",
    "ax.plot([0, max_rank], [0, max_rank], 'k--', alpha=0.5, label='Perfect Agreement')\n",
    "\n",
    "# Annotate outliers (biggest disagreements)\n",
    "outliers = espn_ranked[abs(espn_ranked['ML_vs_ESPN']) > 75]\n",
    "for _, row in outliers.iterrows():\n",
    "    ax.annotate(row['Name'], (row['ESPN_Rank'], row['ML_Rank']), \n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('ESPN Rank', fontsize=12)\n",
    "ax.set_ylabel('ML Rank (PAR-adjusted)', fontsize=12)\n",
    "ax.set_title('ML Model vs ESPN Rankings', fontsize=14)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "r, p = stats.spearmanr(espn_ranked['ESPN_Rank'], espn_ranked['ML_Rank'])\n",
    "print(f\"Spearman correlation: r = {r:.3f}, p = {p:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FanGraphs vs ESPN\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.regplot(data=espn_ranked, x='ESPN_Rank', y='FG_Rank',\n",
    "            scatter_kws={'alpha': 0.5, 's': 30},\n",
    "            line_kws={'color': 'red', 'linewidth': 2},\n",
    "            ax=ax)\n",
    "\n",
    "max_rank = max(espn_ranked['ESPN_Rank'].max(), espn_ranked['FG_Rank'].max())\n",
    "ax.plot([0, max_rank], [0, max_rank], 'k--', alpha=0.5, label='Perfect Agreement')\n",
    "\n",
    "outliers = espn_ranked[abs(espn_ranked['FG_vs_ESPN']) > 75]\n",
    "for _, row in outliers.iterrows():\n",
    "    ax.annotate(row['Name'], (row['ESPN_Rank'], row['FG_Rank']),\n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('ESPN Rank', fontsize=12)\n",
    "ax.set_ylabel('FanGraphs Rank (PAR-adjusted)', fontsize=12)\n",
    "ax.set_title('FanGraphs Projections vs ESPN Rankings', fontsize=14)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "r, p = stats.spearmanr(espn_ranked['ESPN_Rank'], espn_ranked['FG_Rank'])\n",
    "print(f\"Spearman correlation: r = {r:.3f}, p = {p:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML vs FanGraphs\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.regplot(data=espn_ranked, x='FG_Rank', y='ML_Rank',\n",
    "            scatter_kws={'alpha': 0.5, 's': 30},\n",
    "            line_kws={'color': 'red', 'linewidth': 2},\n",
    "            ax=ax)\n",
    "\n",
    "max_rank = max(espn_ranked['FG_Rank'].max(), espn_ranked['ML_Rank'].max())\n",
    "ax.plot([0, max_rank], [0, max_rank], 'k--', alpha=0.5, label='Perfect Agreement')\n",
    "\n",
    "outliers = espn_ranked[abs(espn_ranked['ML_vs_FG']) > 50]\n",
    "for _, row in outliers.iterrows():\n",
    "    ax.annotate(row['Name'], (row['FG_Rank'], row['ML_Rank']),\n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('FanGraphs Rank (PAR-adjusted)', fontsize=12)\n",
    "ax.set_ylabel('ML Rank (PAR-adjusted)', fontsize=12)\n",
    "ax.set_title('ML Model vs FanGraphs Projections', fontsize=14)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "r, p = stats.spearmanr(espn_ranked['FG_Rank'], espn_ranked['ML_Rank'])\n",
    "print(f\"Spearman correlation: r = {r:.3f}, p = {p:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rank Difference Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# ML vs ESPN\n",
    "axes[0].hist(espn_ranked['ML_vs_ESPN'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].axvline(x=espn_ranked['ML_vs_ESPN'].mean(), color='green', linestyle='-', linewidth=2, label=f\"Mean: {espn_ranked['ML_vs_ESPN'].mean():.1f}\")\n",
    "axes[0].set_xlabel('ML Rank - ESPN Rank', fontsize=11)\n",
    "axes[0].set_ylabel('Count', fontsize=11)\n",
    "axes[0].set_title('ML vs ESPN\\n(Positive = ML ranks higher)', fontsize=12)\n",
    "axes[0].legend()\n",
    "\n",
    "# FG vs ESPN\n",
    "axes[1].hist(espn_ranked['FG_vs_ESPN'], bins=30, edgecolor='black', alpha=0.7, color='darkorange')\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].axvline(x=espn_ranked['FG_vs_ESPN'].mean(), color='green', linestyle='-', linewidth=2, label=f\"Mean: {espn_ranked['FG_vs_ESPN'].mean():.1f}\")\n",
    "axes[1].set_xlabel('FG Rank - ESPN Rank', fontsize=11)\n",
    "axes[1].set_ylabel('Count', fontsize=11)\n",
    "axes[1].set_title('FanGraphs vs ESPN\\n(Positive = FG ranks higher)', fontsize=12)\n",
    "axes[1].legend()\n",
    "\n",
    "# ML vs FG\n",
    "axes[2].hist(espn_ranked['ML_vs_FG'], bins=30, edgecolor='black', alpha=0.7, color='forestgreen')\n",
    "axes[2].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[2].axvline(x=espn_ranked['ML_vs_FG'].mean(), color='blue', linestyle='-', linewidth=2, label=f\"Mean: {espn_ranked['ML_vs_FG'].mean():.1f}\")\n",
    "axes[2].set_xlabel('ML Rank - FG Rank', fontsize=11)\n",
    "axes[2].set_ylabel('Count', fontsize=11)\n",
    "axes[2].set_title('ML vs FanGraphs\\n(Positive = ML ranks higher)', fontsize=12)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.suptitle('Rank Difference Distributions (ESPN-Ranked Players)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary stats\n",
    "print(\"\\nRank Difference Summary Statistics:\")\n",
    "print(\"=\"*60)\n",
    "for col, name in [('ML_vs_ESPN', 'ML vs ESPN'), ('FG_vs_ESPN', 'FG vs ESPN'), ('ML_vs_FG', 'ML vs FG')]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Mean: {espn_ranked[col].mean():+.1f}\")\n",
    "    print(f\"  Median: {espn_ranked[col].median():+.1f}\")\n",
    "    print(f\"  Std Dev: {espn_ranked[col].std():.1f}\")\n",
    "    print(f\"  Range: [{espn_ranked[col].min():.0f}, {espn_ranked[col].max():.0f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plots overlaid\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.kdeplot(data=espn_ranked['ML_vs_ESPN'], ax=ax, label='ML vs ESPN', linewidth=2)\n",
    "sns.kdeplot(data=espn_ranked['FG_vs_ESPN'], ax=ax, label='FG vs ESPN', linewidth=2)\n",
    "sns.kdeplot(data=espn_ranked['ML_vs_FG'], ax=ax, label='ML vs FG', linewidth=2)\n",
    "\n",
    "ax.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Rank Difference', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Rank Difference Distributions (KDE)', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agreement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agreement thresholds\n",
    "thresholds = [5, 10, 20, 30, 50]\n",
    "\n",
    "agreement_stats = []\n",
    "for thresh in thresholds:\n",
    "    ml_espn_agree = (abs(espn_ranked['ML_vs_ESPN']) <= thresh).sum()\n",
    "    fg_espn_agree = (abs(espn_ranked['FG_vs_ESPN']) <= thresh).sum()\n",
    "    ml_fg_agree = (abs(espn_ranked['ML_vs_FG']) <= thresh).sum()\n",
    "    \n",
    "    agreement_stats.append({\n",
    "        'Threshold': f'±{thresh}',\n",
    "        'ML-ESPN': f\"{ml_espn_agree} ({100*ml_espn_agree/len(espn_ranked):.1f}%)\",\n",
    "        'FG-ESPN': f\"{fg_espn_agree} ({100*fg_espn_agree/len(espn_ranked):.1f}%)\",\n",
    "        'ML-FG': f\"{ml_fg_agree} ({100*ml_fg_agree/len(espn_ranked):.1f}%)\",\n",
    "    })\n",
    "\n",
    "agreement_df = pd.DataFrame(agreement_stats)\n",
    "print(\"Players within X ranks of each other:\")\n",
    "print(agreement_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize agreement rates\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(thresholds))\n",
    "width = 0.25\n",
    "\n",
    "ml_espn_pcts = [(abs(espn_ranked['ML_vs_ESPN']) <= t).mean() * 100 for t in thresholds]\n",
    "fg_espn_pcts = [(abs(espn_ranked['FG_vs_ESPN']) <= t).mean() * 100 for t in thresholds]\n",
    "ml_fg_pcts = [(abs(espn_ranked['ML_vs_FG']) <= t).mean() * 100 for t in thresholds]\n",
    "\n",
    "ax.bar(x - width, ml_espn_pcts, width, label='ML vs ESPN', color='steelblue')\n",
    "ax.bar(x, fg_espn_pcts, width, label='FG vs ESPN', color='darkorange')\n",
    "ax.bar(x + width, ml_fg_pcts, width, label='ML vs FG', color='forestgreen')\n",
    "\n",
    "ax.set_xlabel('Agreement Threshold (±ranks)', fontsize=12)\n",
    "ax.set_ylabel('% of Players', fontsize=12)\n",
    "ax.set_title('Ranking Agreement Rates', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'±{t}' for t in thresholds])\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Add percentage labels\n",
    "for i, (ml, fg, mlfg) in enumerate(zip(ml_espn_pcts, fg_espn_pcts, ml_fg_pcts)):\n",
    "    ax.text(i - width, ml + 2, f'{ml:.0f}%', ha='center', fontsize=9)\n",
    "    ax.text(i, fg + 2, f'{fg:.0f}%', ha='center', fontsize=9)\n",
    "    ax.text(i + width, mlfg + 2, f'{mlfg:.0f}%', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Biggest Disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players where ML ranks MUCH higher than ESPN\n",
    "print(\"=\" * 80)\n",
    "print(\"ML Model's SLEEPERS (ML ranks much higher than ESPN):\")\n",
    "print(\"=\" * 80)\n",
    "ml_sleepers = espn_ranked.nlargest(15, 'ML_vs_ESPN')[['Name', 'Team', 'Position', 'Type', 'ML_Rank', 'ESPN_Rank', 'ML_vs_ESPN']]\n",
    "print(ml_sleepers.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players where ESPN ranks MUCH higher than ML\n",
    "print(\"=\" * 80)\n",
    "print(\"ML Model's FADES (ESPN ranks much higher than ML):\")\n",
    "print(\"=\" * 80)\n",
    "ml_fades = espn_ranked.nsmallest(15, 'ML_vs_ESPN')[['Name', 'Team', 'Position', 'Type', 'ML_Rank', 'ESPN_Rank', 'ML_vs_ESPN']]\n",
    "print(ml_fades.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players where FanGraphs ranks MUCH higher than ESPN\n",
    "print(\"=\" * 80)\n",
    "print(\"FanGraphs SLEEPERS (FG ranks much higher than ESPN):\")\n",
    "print(\"=\" * 80)\n",
    "fg_sleepers = espn_ranked.nlargest(15, 'FG_vs_ESPN')[['Name', 'Team', 'Position', 'Type', 'FG_Rank', 'ESPN_Rank', 'FG_vs_ESPN']]\n",
    "print(fg_sleepers.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players where ESPN ranks MUCH higher than FanGraphs\n",
    "print(\"=\" * 80)\n",
    "print(\"FanGraphs FADES (ESPN ranks much higher than FG):\")\n",
    "print(\"=\" * 80)\n",
    "fg_fades = espn_ranked.nsmallest(15, 'FG_vs_ESPN')[['Name', 'Team', 'Position', 'Type', 'FG_Rank', 'ESPN_Rank', 'FG_vs_ESPN']]\n",
    "print(fg_fades.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players where ML and FG strongly disagree\n",
    "print(\"=\" * 80)\n",
    "print(\"ML vs FanGraphs Disagreements (ML ranks higher):\")\n",
    "print(\"=\" * 80)\n",
    "ml_over_fg = espn_ranked.nlargest(10, 'ML_vs_FG')[['Name', 'Team', 'Position', 'Type', 'ML_Rank', 'FG_Rank', 'ML_vs_FG']]\n",
    "print(ml_over_fg.to_string(index=False))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"ML vs FanGraphs Disagreements (FG ranks higher):\")\n",
    "print(\"=\" * 80)\n",
    "fg_over_ml = espn_ranked.nsmallest(10, 'ML_vs_FG')[['Name', 'Team', 'Position', 'Type', 'ML_Rank', 'FG_Rank', 'ML_vs_FG']]\n",
    "print(fg_over_ml.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Consensus Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find players where ALL THREE systems agree (within 20 ranks)\n",
    "consensus_thresh = 20\n",
    "espn_ranked['all_agree'] = (\n",
    "    (abs(espn_ranked['ML_vs_ESPN']) <= consensus_thresh) & \n",
    "    (abs(espn_ranked['FG_vs_ESPN']) <= consensus_thresh) & \n",
    "    (abs(espn_ranked['ML_vs_FG']) <= consensus_thresh)\n",
    ")\n",
    "\n",
    "consensus_players = espn_ranked[espn_ranked['all_agree']].sort_values('ESPN_Rank')\n",
    "print(f\"Players where all 3 systems agree (within ±{consensus_thresh} ranks): {len(consensus_players)}\")\n",
    "print(f\"That's {100*len(consensus_players)/len(espn_ranked):.1f}% of ESPN-ranked players\")\n",
    "print(\"\\nTop 30 consensus players:\")\n",
    "print(consensus_players.head(30)[['Name', 'Team', 'Position', 'ML_Rank', 'FG_Rank', 'ESPN_Rank']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players where NO systems agree\n",
    "no_consensus = espn_ranked[\n",
    "    (abs(espn_ranked['ML_vs_ESPN']) > 30) & \n",
    "    (abs(espn_ranked['FG_vs_ESPN']) > 30)\n",
    "].sort_values('ESPN_Rank')\n",
    "\n",
    "print(f\"\\nPlayers with major disagreements (ML & FG both >30 from ESPN): {len(no_consensus)}\")\n",
    "print(no_consensus[['Name', 'Team', 'Position', 'ML_Rank', 'FG_Rank', 'ESPN_Rank', 'ML_vs_ESPN', 'FG_vs_ESPN']].head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis by Position/Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations by player type\n",
    "print(\"Spearman Correlations by Player Type:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for ptype in ['Batter', 'SP', 'RP']:\n",
    "    subset = espn_ranked[espn_ranked['Type'] == ptype]\n",
    "    if len(subset) > 10:\n",
    "        r_ml_espn = stats.spearmanr(subset['ML_Rank'], subset['ESPN_Rank'])[0]\n",
    "        r_fg_espn = stats.spearmanr(subset['FG_Rank'], subset['ESPN_Rank'])[0]\n",
    "        r_ml_fg = stats.spearmanr(subset['ML_Rank'], subset['FG_Rank'])[0]\n",
    "        print(f\"\\n{ptype} (n={len(subset)}):\")\n",
    "        print(f\"  ML-ESPN: {r_ml_espn:.3f}\")\n",
    "        print(f\"  FG-ESPN: {r_fg_espn:.3f}\")\n",
    "        print(f\"  ML-FG:   {r_ml_fg:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of rank differences by type\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, (col, title) in zip(axes, [\n",
    "    ('ML_vs_ESPN', 'ML vs ESPN'),\n",
    "    ('FG_vs_ESPN', 'FG vs ESPN'),\n",
    "    ('ML_vs_FG', 'ML vs FG')\n",
    "]):\n",
    "    sns.boxplot(data=espn_ranked, x='Type', y=col, ax=ax, order=['Batter', 'SP', 'RP'])\n",
    "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Rank Difference')\n",
    "\n",
    "plt.suptitle('Rank Differences by Player Type', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean differences by type\n",
    "type_summary = espn_ranked.groupby('Type').agg({\n",
    "    'ML_vs_ESPN': ['mean', 'std'],\n",
    "    'FG_vs_ESPN': ['mean', 'std'],\n",
    "    'ML_vs_FG': ['mean', 'std'],\n",
    "}).round(1)\n",
    "\n",
    "print(\"\\nMean Rank Differences by Player Type:\")\n",
    "print(type_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by ESPN draft tier\n",
    "espn_ranked['ESPN_Tier'] = pd.cut(\n",
    "    espn_ranked['ESPN_Rank'],\n",
    "    bins=[0, 25, 50, 100, 150, 200, 300],\n",
    "    labels=['Top 25', '26-50', '51-100', '101-150', '151-200', '200+']\n",
    ")\n",
    "\n",
    "tier_corr = []\n",
    "for tier in ['Top 25', '26-50', '51-100', '101-150', '151-200', '200+']:\n",
    "    subset = espn_ranked[espn_ranked['ESPN_Tier'] == tier]\n",
    "    if len(subset) > 5:\n",
    "        r_ml = stats.spearmanr(subset['ML_Rank'], subset['ESPN_Rank'])[0]\n",
    "        r_fg = stats.spearmanr(subset['FG_Rank'], subset['ESPN_Rank'])[0]\n",
    "        tier_corr.append({'Tier': tier, 'n': len(subset), 'ML-ESPN': r_ml, 'FG-ESPN': r_fg})\n",
    "\n",
    "tier_df = pd.DataFrame(tier_corr)\n",
    "print(\"Correlations by ESPN Draft Tier:\")\n",
    "print(tier_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots faceted by tier\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, tier in zip(axes, ['Top 25', '26-50', '51-100', '101-150', '151-200', '200+']):\n",
    "    subset = espn_ranked[espn_ranked['ESPN_Tier'] == tier]\n",
    "    if len(subset) > 0:\n",
    "        ax.scatter(subset['ESPN_Rank'], subset['ML_Rank'], alpha=0.6, label='ML', s=30)\n",
    "        ax.scatter(subset['ESPN_Rank'], subset['FG_Rank'], alpha=0.6, label='FG', s=30, marker='^')\n",
    "        \n",
    "        # Add perfect agreement line\n",
    "        min_r, max_r = subset['ESPN_Rank'].min(), subset['ESPN_Rank'].max()\n",
    "        ax.plot([min_r, max_r], [min_r, max_r], 'k--', alpha=0.3)\n",
    "        \n",
    "        ax.set_title(f'{tier} (n={len(subset)})', fontsize=11)\n",
    "        ax.set_xlabel('ESPN Rank')\n",
    "        ax.set_ylabel('ML/FG Rank')\n",
    "        ax.legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Rankings by ESPN Tier', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RANKINGS COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nDataset: {len(espn_ranked)} ESPN-ranked players\")\n",
    "print(f\"  Batters: {len(espn_ranked[espn_ranked['Type'] == 'Batter'])}\")\n",
    "print(f\"  Starting Pitchers: {len(espn_ranked[espn_ranked['Type'] == 'SP'])}\")\n",
    "print(f\"  Relief Pitchers: {len(espn_ranked[espn_ranked['Type'] == 'RP'])}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"OVERALL CORRELATIONS (Spearman):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"  ML vs ESPN:       {stats.spearmanr(espn_ranked['ML_Rank'], espn_ranked['ESPN_Rank'])[0]:.3f}\")\n",
    "print(f\"  FanGraphs vs ESPN: {stats.spearmanr(espn_ranked['FG_Rank'], espn_ranked['ESPN_Rank'])[0]:.3f}\")\n",
    "print(f\"  ML vs FanGraphs:   {stats.spearmanr(espn_ranked['ML_Rank'], espn_ranked['FG_Rank'])[0]:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"AGREEMENT RATES:\")\n",
    "print(\"-\" * 80)\n",
    "for thresh in [10, 20, 30]:\n",
    "    ml_espn = (abs(espn_ranked['ML_vs_ESPN']) <= thresh).mean() * 100\n",
    "    fg_espn = (abs(espn_ranked['FG_vs_ESPN']) <= thresh).mean() * 100\n",
    "    ml_fg = (abs(espn_ranked['ML_vs_FG']) <= thresh).mean() * 100\n",
    "    print(f\"  Within ±{thresh} ranks: ML-ESPN {ml_espn:.1f}% | FG-ESPN {fg_espn:.1f}% | ML-FG {ml_fg:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"SYSTEMATIC BIASES (Mean Rank Differences):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"  ML vs ESPN:  {espn_ranked['ML_vs_ESPN'].mean():+.1f} (positive = ML ranks higher)\")\n",
    "print(f\"  FG vs ESPN:  {espn_ranked['FG_vs_ESPN'].mean():+.1f} (positive = FG ranks higher)\")\n",
    "print(f\"  ML vs FG:    {espn_ranked['ML_vs_FG'].mean():+.1f} (positive = ML ranks higher)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization: Joint pair plot\n",
    "g = sns.pairplot(\n",
    "    espn_ranked[['ML_Rank', 'FG_Rank', 'ESPN_Rank', 'Type']],\n",
    "    hue='Type',\n",
    "    diag_kind='kde',\n",
    "    plot_kws={'alpha': 0.5, 's': 25},\n",
    "    height=3\n",
    ")\n",
    "g.fig.suptitle('Pairwise Rank Comparisons by Player Type', y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
